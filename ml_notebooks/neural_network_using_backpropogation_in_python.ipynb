{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP2xdzRnFsuEtKpEpsh0lbe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["Based on Ajay Srinivas' YouTube video.$^*$\n","\n","\\* [youtu.be/7qYtIveJ6hU](https://youtu.be/7qYtIveJ6hU)"],"metadata":{"id":"YV0cKtdUY-Wr"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"GVLzlQckU3vA","executionInfo":{"status":"ok","timestamp":1666974063668,"user_tz":-480,"elapsed":7,"user":{"displayName":"Sascha Robitzki","userId":"17419209573331928568"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","source":["X = hours sleeping, hours studying <br/>\n","Y = test score of the student"],"metadata":{"id":"eg32zdJ5VMoU"}},{"cell_type":"code","source":["X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n","y = np.array(([92], [86], [89]), dtype=float)\n","\n","print(f'X.shape = {X.shape}')\n","print(X)\n","print(f'y.shape = {y.shape}')\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rRrsnvGVGSE","executionInfo":{"status":"ok","timestamp":1666972310335,"user_tz":-480,"elapsed":643,"user":{"displayName":"Sascha Robitzki","userId":"17419209573331928568"}},"outputId":"c21ff7fc-be08-4529-bd19-d90262561b25"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["X.shape = (3, 2)\n","[[2. 9.]\n"," [1. 5.]\n"," [3. 6.]]\n","y.shape = (3, 1)\n","[[92.]\n"," [86.]\n"," [89.]]\n"]}]},{"cell_type":"code","source":["# Scale units\n","\n","X = X / np.amax(X, axis=0) # maximum of X array\n","print(X)\n","\n","y /= 100 # maximum test score is 100\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGhI9KajWmpv","executionInfo":{"status":"ok","timestamp":1666972311812,"user_tz":-480,"elapsed":3,"user":{"displayName":"Sascha Robitzki","userId":"17419209573331928568"}},"outputId":"8194b93a-1251-4c28-ee0f-465eab00522c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.66666667 1.        ]\n"," [0.33333333 0.55555556]\n"," [1.         0.66666667]]\n","[[0.92]\n"," [0.86]\n"," [0.89]]\n"]}]},{"cell_type":"code","source":["def sigmoid(x, diff:bool=False) -> np.ndarray:\n","    if diff == True:\n","        return x * (1 - x)\n","    return 1 / (1 + np.exp(- x))\n","\n","class NeuralNetwork(object):\n","    # layers\n","    a0 = None # input\n","    z1 = None # hidden\n","    z2 = None # output\n","\n","    def __init__(self, n_input:int=2, n_hidden:int=3, n_output:int=1):\n","        # parameters\n","        self.input_size = n_input\n","        self.hidden_size = n_hidden\n","        self.output_size = n_output\n","\n","        # weights\n","        self.W1 = np.random.randn(self.input_size, self.hidden_size) # 3 x 2 weight matrix from input to hidden layer\n","        self.W2 = np.random.rand(self.hidden_size, self.output_size) # 3 x 1 weight matrix from hidden to output layer\n","\n","    def forward(self, X) -> np.ndarray:\n","        # forward propagation through the network\n","\n","        self.a0 = np.dot(X, self.W1) # dot product of X (input) and first set of weights (3x2)\n","        self.z1 = sigmoid(self.a0) # activation function\n","        self.z2 = np.dot(self.z1, self.W2) # dot product of hidden layer (z1) and second set of weights (3x1)\n","        output = sigmoid(self.z2)\n","\n","        return output\n","\n","    def backward(self, X, y, output):\n","        # backward propagate through the network\n","\n","        self.output_delta = (y - output) * sigmoid(output, diff=True)\n","\n","        # how much the hidden layer's weights contribute to the output error,\n","        # and applying the derivative of sigmoid\n","        self.z1_delta = (self.output_delta.dot(self.W2.T)) * sigmoid(self.z1, diff=True)\n","\n","        self.W1 += X.T.dot(self.z1_delta) # adjusting first set (input -> hidden) weights\n","        self.W2 += self.z1.T.dot(self.output_delta) # adjusting second set (hidden -> output) weights\n","\n","    def train(self, X, y):\n","        output = self.forward(X)\n","\n","        self.backward(X, y, output)\n","\n","nn = NeuralNetwork()\n","\n","for n in range(2000):\n","    if n % 100 == 0:\n","        print(f'Loss: {np.mean(np.square(y - nn.forward(X)))}')\n","    nn.train(X, y)\n","\n","print(f'Input = {X}\\n')\n","print(f'Labels = {y}\\n')\n","print(f'Loss = {np.mean(np.square(y - nn.forward(X)))}\\n')\n","print(f'Predicted output = {nn.forward(X)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChK5-sgnXX70","executionInfo":{"status":"ok","timestamp":1666973063625,"user_tz":-480,"elapsed":7,"user":{"displayName":"Sascha Robitzki","userId":"17419209573331928568"}},"outputId":"9da5c200-7dd8-4c1a-a455-f1679b4311d9"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 0.05317533495623807\n","Loss: 0.0006996535270323659\n","Loss: 0.0006383563330344674\n","Loss: 0.000591215485320353\n","Loss: 0.0005512237413459965\n","Loss: 0.0005170448811003311\n","Loss: 0.0004876138151372342\n","Loss: 0.000462080975429211\n","Loss: 0.00043976775654994805\n","Loss: 0.00042013025549192157\n","Loss: 0.00040273052855087994\n","Loss: 0.0003872140824913623\n","Loss: 0.00037329234608837134\n","Loss: 0.00036072904075205647\n","Loss: 0.0003493295711990885\n","Loss: 0.00033893274382426923\n","Loss: 0.000329404276896309\n","Loss: 0.00032063169161889306\n","Loss: 0.00031252027020615275\n","Loss: 0.0003049898415041487\n","Input = [[0.66666667 1.        ]\n"," [0.33333333 0.55555556]\n"," [1.         0.66666667]]\n","\n","Labels = [[0.92]\n"," [0.86]\n"," [0.89]]\n","\n","Loss = 0.0002979722112243342\n","\n","Predicted output = [[0.89621554]\n"," [0.86815943]\n"," [0.90617529]]\n"]}]}]}